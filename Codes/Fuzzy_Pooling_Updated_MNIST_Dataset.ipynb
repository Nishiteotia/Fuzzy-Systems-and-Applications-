{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inxlLEiVaIGG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApmhBHSVJp_Y"
      },
      "outputs": [],
      "source": [
        "class MaxPoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2):\n",
        "        \"\"\"\n",
        "        Max Pooling Layer (Custom Implementation).\n",
        "        :param pool_size: Size of the pooling window.\n",
        "        \"\"\"\n",
        "        super(MaxPoolingLayer, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the max-pooling layer.\n",
        "        \"\"\"\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        output_height, output_width = height // self.pool_size, width // self.pool_size\n",
        "\n",
        "        # Initialize output tensor\n",
        "        pooled_output = torch.zeros((batch_size, channels, output_height, output_width)).to(x.device)\n",
        "\n",
        "        # Loop over pooling windows\n",
        "        for i in range(0, height, self.pool_size):\n",
        "            for j in range(0, width, self.pool_size):\n",
        "                # Extract the current pooling window\n",
        "                window = x[:, :, i:i + self.pool_size, j:j + self.pool_size]\n",
        "\n",
        "                # Compute the maximum value in the window\n",
        "                max_value = torch.max(window.reshape(batch_size, channels, -1), dim=2)[0]\n",
        "\n",
        "                # Assign the max value to the corresponding location in the output tensor\n",
        "                pooled_output[:, :, i // self.pool_size, j // self.pool_size] = max_value\n",
        "\n",
        "        return pooled_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlVuCGcoJ3Hs"
      },
      "outputs": [],
      "source": [
        "class MaxPoolingCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Max Pooling Layer.\n",
        "        \"\"\"\n",
        "        super(MaxPoolingCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # conv1 has 32 filters, so it produces 32 output channels\n",
        "        self.max_pool = MaxPoolingLayer(pool_size=2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # First convolutional layer\n",
        "        x = self.max_pool(x)       # First max pooling\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)            # Fully connected layer to output classes\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKxgghRGaL8I"
      },
      "outputs": [],
      "source": [
        "class FuzzyPoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2):\n",
        "        \"\"\"\n",
        "        Fuzzy Pooling Layer\n",
        "        :param pool_size: Size of pooling window\n",
        "        \"\"\"\n",
        "        super(FuzzyPoolingLayer, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    def gaussian_membership(self, x, mean, std):\n",
        "        \"\"\"\n",
        "        Compute Gaussian Membership Function (GMF) for input tensor.\n",
        "        \"\"\"\n",
        "        return torch.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the fuzzy-based pooling layer.\n",
        "        \"\"\"\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        output_height, output_width = height // self.pool_size, width // self.pool_size\n",
        "\n",
        "        # Initialize pooled output\n",
        "        pooled_output = torch.zeros((batch_size, channels, output_height, output_width)).to(x.device)\n",
        "\n",
        "        # Loop over pooling windows\n",
        "        for i in range(0, height, self.pool_size):\n",
        "            for j in range(0, width, self.pool_size):\n",
        "                # Extract the current pooling window\n",
        "                window = x[:, :, i:i + self.pool_size, j:j + self.pool_size]\n",
        "\n",
        "                # Compute mean and standard deviation for the window\n",
        "                mean = window.mean(dim=(2, 3), keepdim=True)\n",
        "                std = window.std(dim=(2, 3), keepdim=True) + 1e-8  # Avoid divide-by-zero\n",
        "\n",
        "                # Compute GMF (Gaussian Membership Function) values for the window\n",
        "                gmf = self.gaussian_membership(window, mean, std)\n",
        "\n",
        "                # Threshold: S-norm (max) followed by T-norm (min)\n",
        "                threshold = torch.min(torch.max(gmf, dim=3)[0], dim=2)[0].unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "                # Identify dominant features (only keep elements above the threshold)\n",
        "                dominant_features = window * (gmf >= threshold).float()\n",
        "\n",
        "                # Compute weighted average of the dominant features\n",
        "                weights = gmf / (gmf.sum(dim=(2, 3), keepdim=True) + 1e-8)\n",
        "                pooled_value = (dominant_features * weights).sum(dim=(2, 3))\n",
        "\n",
        "                # Assign the pooled value to the corresponding location in the output tensor\n",
        "                pooled_output[:, :, i // self.pool_size, j // self.pool_size] = pooled_value\n",
        "\n",
        "        return pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOfeAi9FaQRy"
      },
      "outputs": [],
      "source": [
        "class FuzzyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Fuzzy-Based Pooling Layer.\n",
        "        \"\"\"\n",
        "        super(FuzzyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  ## self.conv1 = nn.Conv2d(in_channels=3 (RGB), out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fuzzy_pool = FuzzyPoolingLayer(pool_size=2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.fuzzy_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-6stMz2J8xR"
      },
      "outputs": [],
      "source": [
        "# Training function with loss & accuracy tracking\n",
        "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "\n",
        "    # Lists to store loss and accuracy per epoch for plotting\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Compute average loss and accuracy for this epoch\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        # Store values for plotting\n",
        "        epoch_losses.append(avg_loss)\n",
        "        epoch_accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function to evaluate the model on test data\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "ojCr1WZU4CQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to plot loss and accuracy\n",
        "def plot_metrics(losses, accuracies):\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, losses, '-o', label='Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracies, '-o', label='Accuracy', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2EZLvb7d4Ggl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5KgxNvTKFOp"
      },
      "outputs": [],
      "source": [
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    from torchvision.datasets import MNIST\n",
        "    from torchvision.transforms import ToTensor\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load dataset\n",
        "    train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    test_dataset = MNIST(root='data/', train=False, transform=ToTensor(), download=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HbsGaRbK11G",
        "outputId": "2184b5f9-4480-41bd-f6be-d0a36cd03708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.2355, Accuracy: 93.22%\n",
            "Epoch [2/5], Loss: 0.0869, Accuracy: 97.46%\n",
            "Epoch [3/5], Loss: 0.0650, Accuracy: 98.12%\n",
            "Epoch [4/5], Loss: 0.0533, Accuracy: 98.44%\n",
            "Epoch [5/5], Loss: 0.0460, Accuracy: 98.66%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelMax = MaxPoolingCNN(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelMax.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelMax, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelMax, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "BZj7QpU5s4-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201c17c5-7aed-43ab-c2a5-acc355afa556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0549, Test Accuracy: 98.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZnTNRtGaZgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d94de2-c8e4-4cf4-a737-7f7d3427260e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3223, Accuracy: 91.05%\n",
            "Epoch [2/5], Loss: 0.1308, Accuracy: 96.29%\n",
            "Epoch [3/5], Loss: 0.0918, Accuracy: 97.39%\n",
            "Epoch [4/5], Loss: 0.0728, Accuracy: 97.88%\n",
            "Epoch [5/5], Loss: 0.0624, Accuracy: 98.22%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelFuzzy = FuzzyCNN(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelFuzzy.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelFuzzy, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelFuzzy, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "3GmBb-y7s7vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6a640e-edb5-491e-e158-220def666d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0674, Test Accuracy: 97.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU0QgOGcSmVK"
      },
      "outputs": [],
      "source": [
        "class AveragePoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2):\n",
        "        \"\"\"\n",
        "        Average Pooling Layer\n",
        "        :param pool_size: Size of pooling window\n",
        "        \"\"\"\n",
        "        super(AveragePoolingLayer, self).__init__()\n",
        "        self.pool = nn.AvgPool2d(kernel_size=pool_size, stride=pool_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pool(x)\n",
        "\n",
        "\n",
        "class CNNWithAveragePooling(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Average Pooling Layer.\n",
        "        \"\"\"\n",
        "        super(CNNWithAveragePooling, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.avg_pool = AveragePoolingLayer(pool_size=2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-s8mEApSqw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6c8a5f-9f10-4878-86ff-22e33a2be9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.2835, Accuracy: 92.03%\n",
            "Epoch [2/5], Loss: 0.1069, Accuracy: 97.04%\n",
            "Epoch [3/5], Loss: 0.0758, Accuracy: 97.84%\n",
            "Epoch [4/5], Loss: 0.0632, Accuracy: 98.19%\n",
            "Epoch [5/5], Loss: 0.0530, Accuracy: 98.48%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelAvg = CNNWithAveragePooling(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelAvg.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelAvg, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelAvg, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "XcrmAGZ8tCRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9900286f-baa8-4241-b26c-c33016e09048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0541, Test Accuracy: 98.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzEe0YLnnvky"
      },
      "outputs": [],
      "source": [
        "class FuzzyPoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2, reg_lambda=0.01):\n",
        "        \"\"\"\n",
        "        Fuzzy Pooling Layer with RegP (Regularization by Pooling).\n",
        "        :param pool_size: Size of pooling window\n",
        "        :param reg_lambda: Regularization factor to control sparsity.\n",
        "        \"\"\"\n",
        "        super(FuzzyPoolingLayer, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "        self.reg_lambda = reg_lambda  # Controls regularization strength\n",
        "\n",
        "    def gaussian_membership(self, x, mean, std):\n",
        "        \"\"\"\n",
        "        Compute Gaussian Membership Function (GMF) for input tensor.\n",
        "        \"\"\"\n",
        "        return torch.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
        "\n",
        "    def regularization_penalty(self, gmf):\n",
        "        \"\"\"\n",
        "        RegP: Compute the regularization penalty for GMF activations.\n",
        "        This penalty encourages sparse activations to reduce redundancy.\n",
        "        \"\"\"\n",
        "        # L2 norm regularization over the GMF values to penalize dense activations\n",
        "        penalty = torch.sum(gmf ** 2, dim=(2, 3))  # Sum over spatial dimensions\n",
        "        return self.reg_lambda * penalty.mean()  # Apply lambda and take mean\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the fuzzy-based pooling layer with RegP.\n",
        "        \"\"\"\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        output_height, output_width = height // self.pool_size, width // self.pool_size\n",
        "\n",
        "        # Initialize pooled output\n",
        "        pooled_output = torch.zeros((batch_size, channels, output_height, output_width)).to(x.device)\n",
        "        regp_total = 0  # Store the total RegP penalty\n",
        "\n",
        "        # Loop over pooling windows\n",
        "        for i in range(0, height, self.pool_size):\n",
        "            for j in range(0, width, self.pool_size):\n",
        "                # Extract the current pooling window\n",
        "                window = x[:, :, i:i + self.pool_size, j:j + self.pool_size]\n",
        "\n",
        "                # Compute mean and standard deviation for the window\n",
        "                mean = window.mean(dim=(2, 3), keepdim=True)\n",
        "                std = window.std(dim=(2, 3), keepdim=True) + 1e-8  # Avoid divide-by-zero\n",
        "\n",
        "                # Compute GMF (Gaussian Membership Function) values for the window\n",
        "                gmf = self.gaussian_membership(window, mean, std)\n",
        "\n",
        "                # Apply RegP to penalize dense activations\n",
        "                regp_total += self.regularization_penalty(gmf)\n",
        "\n",
        "                # Threshold: S-norm (max) followed by T-norm (min)\n",
        "                threshold = torch.min(torch.max(gmf, dim=3)[0], dim=2)[0].unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "                # Identify dominant features (only keep elements above the threshold)\n",
        "                dominant_features = window * (gmf >= threshold).float()\n",
        "\n",
        "                # Compute weighted average of the dominant features\n",
        "                weights = gmf / (gmf.sum(dim=(2, 3), keepdim=True) + 1e-8)\n",
        "                pooled_value = (dominant_features * weights).sum(dim=(2, 3))\n",
        "\n",
        "                # Assign the pooled value to the corresponding location in the output tensor\n",
        "                pooled_output[:, :, i // self.pool_size, j // self.pool_size] = pooled_value\n",
        "\n",
        "        # Add RegP penalty to the model as a regularization loss\n",
        "        self.regp_loss = regp_total / (batch_size * channels)  # Normalize by batch size and channels\n",
        "        return pooled_output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FuzzyCNNWithRegP(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Fuzzy-Based Pooling Layer and RegP.\n",
        "        \"\"\"\n",
        "        super(FuzzyCNNWithRegP, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fuzzy_pool = FuzzyPoolingLayer(pool_size=2, reg_lambda=0.01)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.fuzzy_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def get_regp_loss(self):\n",
        "        \"\"\"\n",
        "        Retrieve the RegP loss from the pooling layer.\n",
        "        \"\"\"\n",
        "        return self.fuzzy_pool.regp_loss"
      ],
      "metadata": {
        "id": "NeFEnZbEKnMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKIeVpKonyF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1035fba1-5024-4f7f-b30a-a7d84fda7796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3376, Accuracy: 90.60%\n",
            "Epoch [2/5], Loss: 0.1423, Accuracy: 95.97%\n",
            "Epoch [3/5], Loss: 0.0975, Accuracy: 97.17%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelR = FuzzyCNNWithRegP(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelR.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelR, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelR, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "3Ls7MxMhtGCo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "22598195-cd57-427e-9f02-51acda17af8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b565e3fb69a3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "JfD8_DQUclOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbDP6VyzNlgY"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def model_summary(model, input_size=(1, 28, 28)):\n",
        "    \"\"\"\n",
        "    Print a summary of the model, including layers, output shapes, and parameter counts.\n",
        "\n",
        "    :param model: PyTorch model instance\n",
        "    :param input_size: Input shape for the model (excluding batch size)\n",
        "    \"\"\"\n",
        "    print(\"----- Model Summary -----\")\n",
        "    print(model)\n",
        "    print(\"\\n----- Layer-wise Details -----\")\n",
        "    summary(model, input_size=input_size)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(\"\\n----- Parameter Details -----\")\n",
        "    print(f\"Total Parameters: {total_params:,}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"Non-trainable Parameters: {total_params - trainable_params:,}\")\n",
        "\n",
        "    # If RegP is present, provide its status.\n",
        "    if hasattr(model, 'get_regp_loss'):\n",
        "        print(\"\\nRegP Enabled: Yes\")\n",
        "    else:\n",
        "        print(\"\\nRegP Enabled: No\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvaHQWqgNuo2"
      },
      "outputs": [],
      "source": [
        "model_summary(modelMax, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic_jDcUtOTiA"
      },
      "outputs": [],
      "source": [
        "model_summary(modelFuzzy, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMmIBzSUOc81"
      },
      "outputs": [],
      "source": [
        "model_summary(modelR, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtlMcmAoOjD5"
      },
      "outputs": [],
      "source": [
        "model_summary(modelAvg, input_size=(1, 28, 28))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}