{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inxlLEiVaIGG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApmhBHSVJp_Y"
      },
      "outputs": [],
      "source": [
        "class MaxPoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2):\n",
        "        \"\"\"\n",
        "        Max Pooling Layer (Custom Implementation).\n",
        "        :param pool_size: Size of the pooling window.\n",
        "        \"\"\"\n",
        "        super(MaxPoolingLayer, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the max-pooling layer.\n",
        "        \"\"\"\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        output_height, output_width = height // self.pool_size, width // self.pool_size\n",
        "\n",
        "        # Initialize output tensor\n",
        "        pooled_output = torch.zeros((batch_size, channels, output_height, output_width)).to(x.device)\n",
        "\n",
        "        # Loop over pooling windows\n",
        "        for i in range(0, height, self.pool_size):\n",
        "            for j in range(0, width, self.pool_size):\n",
        "                # Extract the current pooling window\n",
        "                window = x[:, :, i:i + self.pool_size, j:j + self.pool_size]\n",
        "\n",
        "                # Compute the maximum value in the window\n",
        "                max_value = torch.max(window.reshape(batch_size, channels, -1), dim=2)[0]\n",
        "\n",
        "                # Assign the max value to the corresponding location in the output tensor\n",
        "                pooled_output[:, :, i // self.pool_size, j // self.pool_size] = max_value\n",
        "\n",
        "        return pooled_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlVuCGcoJ3Hs"
      },
      "outputs": [],
      "source": [
        "class MaxPoolingCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Max Pooling Layer.\n",
        "        \"\"\"\n",
        "        super(MaxPoolingCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # conv1 has 32 filters, so it produces 32 output channels\n",
        "        self.max_pool = MaxPoolingLayer(pool_size=2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # First convolutional layer\n",
        "        x = self.max_pool(x)       # First max pooling\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)            # Fully connected layer to output classes\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKxgghRGaL8I"
      },
      "outputs": [],
      "source": [
        "class FuzzyPoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2):\n",
        "        \"\"\"\n",
        "        Fuzzy Pooling Layer\n",
        "        :param pool_size: Size of pooling window\n",
        "        \"\"\"\n",
        "        super(FuzzyPoolingLayer, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    def gaussian_membership(self, x, mean, std):\n",
        "        \"\"\"\n",
        "        Compute Gaussian Membership Function (GMF) for input tensor.\n",
        "        \"\"\"\n",
        "        return torch.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the fuzzy-based pooling layer.\n",
        "        \"\"\"\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        output_height, output_width = height // self.pool_size, width // self.pool_size\n",
        "\n",
        "        # Initialize pooled output\n",
        "        pooled_output = torch.zeros((batch_size, channels, output_height, output_width)).to(x.device)\n",
        "\n",
        "        # Loop over pooling windows\n",
        "        for i in range(0, height, self.pool_size):\n",
        "            for j in range(0, width, self.pool_size):\n",
        "                # Extract the current pooling window\n",
        "                window = x[:, :, i:i + self.pool_size, j:j + self.pool_size]\n",
        "\n",
        "                # Compute mean and standard deviation for the window\n",
        "                mean = window.mean(dim=(2, 3), keepdim=True)\n",
        "                std = window.std(dim=(2, 3), keepdim=True) + 1e-8  # Avoid divide-by-zero\n",
        "\n",
        "                # Compute GMF (Gaussian Membership Function) values for the window\n",
        "                gmf = self.gaussian_membership(window, mean, std)\n",
        "\n",
        "                # Threshold: S-norm (max) followed by T-norm (min)\n",
        "                threshold = torch.min(torch.max(gmf, dim=3)[0], dim=2)[0].unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "                # Identify dominant features (only keep elements above the threshold)\n",
        "                dominant_features = window * (gmf >= threshold).float()\n",
        "\n",
        "                # Compute weighted average of the dominant features\n",
        "                weights = gmf / (gmf.sum(dim=(2, 3), keepdim=True) + 1e-8)\n",
        "                pooled_value = (dominant_features * weights).sum(dim=(2, 3))\n",
        "\n",
        "                # Assign the pooled value to the corresponding location in the output tensor\n",
        "                pooled_output[:, :, i // self.pool_size, j // self.pool_size] = pooled_value\n",
        "\n",
        "        return pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOfeAi9FaQRy"
      },
      "outputs": [],
      "source": [
        "class FuzzyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Fuzzy-Based Pooling Layer.\n",
        "        \"\"\"\n",
        "        super(FuzzyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  ## self.conv1 = nn.Conv2d(in_channels=3 (RGB), out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fuzzy_pool = FuzzyPoolingLayer(pool_size=2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.fuzzy_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-6stMz2J8xR"
      },
      "outputs": [],
      "source": [
        "# Training function with loss & accuracy tracking\n",
        "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "\n",
        "    # Lists to store loss and accuracy per epoch for plotting\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Compute average loss and accuracy for this epoch\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        # Store values for plotting\n",
        "        epoch_losses.append(avg_loss)\n",
        "        epoch_accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function to evaluate the model on test data\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "ojCr1WZU4CQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to plot loss and accuracy\n",
        "def plot_metrics(losses, accuracies):\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, losses, '-o', label='Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracies, '-o', label='Accuracy', color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2EZLvb7d4Ggl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5KgxNvTKFOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd273b8-8fa0-4fde-d3ec-dd8fdf811fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 487kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.77MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.39MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    from torchvision.datasets import MNIST\n",
        "    from torchvision.transforms import ToTensor\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load dataset\n",
        "    train_dataset = MNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    test_dataset = MNIST(root='data/', train=False, transform=ToTensor(), download=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HbsGaRbK11G",
        "outputId": "2184b5f9-4480-41bd-f6be-d0a36cd03708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.2355, Accuracy: 93.22%\n",
            "Epoch [2/5], Loss: 0.0869, Accuracy: 97.46%\n",
            "Epoch [3/5], Loss: 0.0650, Accuracy: 98.12%\n",
            "Epoch [4/5], Loss: 0.0533, Accuracy: 98.44%\n",
            "Epoch [5/5], Loss: 0.0460, Accuracy: 98.66%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelMax = MaxPoolingCNN(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelMax.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelMax, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelMax, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "BZj7QpU5s4-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201c17c5-7aed-43ab-c2a5-acc355afa556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0549, Test Accuracy: 98.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZnTNRtGaZgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d94de2-c8e4-4cf4-a737-7f7d3427260e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3223, Accuracy: 91.05%\n",
            "Epoch [2/5], Loss: 0.1308, Accuracy: 96.29%\n",
            "Epoch [3/5], Loss: 0.0918, Accuracy: 97.39%\n",
            "Epoch [4/5], Loss: 0.0728, Accuracy: 97.88%\n",
            "Epoch [5/5], Loss: 0.0624, Accuracy: 98.22%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelFuzzy = FuzzyCNN(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelFuzzy.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelFuzzy, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelFuzzy, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "3GmBb-y7s7vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6a640e-edb5-491e-e158-220def666d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0674, Test Accuracy: 97.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU0QgOGcSmVK"
      },
      "outputs": [],
      "source": [
        "class AveragePoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2):\n",
        "        \"\"\"\n",
        "        Average Pooling Layer\n",
        "        :param pool_size: Size of pooling window\n",
        "        \"\"\"\n",
        "        super(AveragePoolingLayer, self).__init__()\n",
        "        self.pool = nn.AvgPool2d(kernel_size=pool_size, stride=pool_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pool(x)\n",
        "\n",
        "\n",
        "class CNNWithAveragePooling(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Average Pooling Layer.\n",
        "        \"\"\"\n",
        "        super(CNNWithAveragePooling, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.avg_pool = AveragePoolingLayer(pool_size=2)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-s8mEApSqw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6c8a5f-9f10-4878-86ff-22e33a2be9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.2835, Accuracy: 92.03%\n",
            "Epoch [2/5], Loss: 0.1069, Accuracy: 97.04%\n",
            "Epoch [3/5], Loss: 0.0758, Accuracy: 97.84%\n",
            "Epoch [4/5], Loss: 0.0632, Accuracy: 98.19%\n",
            "Epoch [5/5], Loss: 0.0530, Accuracy: 98.48%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelAvg = CNNWithAveragePooling(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelAvg.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelAvg, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelAvg, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "XcrmAGZ8tCRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9900286f-baa8-4241-b26c-c33016e09048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0541, Test Accuracy: 98.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzEe0YLnnvky"
      },
      "outputs": [],
      "source": [
        "class FuzzyPoolingLayer(nn.Module):\n",
        "    def __init__(self, pool_size=2, reg_lambda=0.01):\n",
        "        \"\"\"\n",
        "        Fuzzy Pooling Layer with RegP (Regularization by Pooling).\n",
        "        :param pool_size: Size of pooling window\n",
        "        :param reg_lambda: Regularization factor to control sparsity.\n",
        "        \"\"\"\n",
        "        super(FuzzyPoolingLayer, self).__init__()\n",
        "        self.pool_size = pool_size\n",
        "        self.reg_lambda = reg_lambda  # Controls regularization strength\n",
        "\n",
        "    def gaussian_membership(self, x, mean, std):\n",
        "        \"\"\"\n",
        "        Compute Gaussian Membership Function (GMF) for input tensor.\n",
        "        \"\"\"\n",
        "        return torch.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
        "\n",
        "    def regularization_penalty(self, gmf):\n",
        "        \"\"\"\n",
        "        RegP: Compute the regularization penalty for GMF activations.\n",
        "        This penalty encourages sparse activations to reduce redundancy.\n",
        "        \"\"\"\n",
        "        # L2 norm regularization over the GMF values to penalize dense activations\n",
        "        penalty = torch.sum(gmf ** 2, dim=(2, 3))  # Sum over spatial dimensions\n",
        "        return self.reg_lambda * penalty.mean()  # Apply lambda and take mean\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the fuzzy-based pooling layer with RegP.\n",
        "        \"\"\"\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        output_height, output_width = height // self.pool_size, width // self.pool_size\n",
        "\n",
        "        # Initialize pooled output\n",
        "        pooled_output = torch.zeros((batch_size, channels, output_height, output_width)).to(x.device)\n",
        "        regp_total = 0  # Store the total RegP penalty\n",
        "\n",
        "        # Loop over pooling windows\n",
        "        for i in range(0, height, self.pool_size):\n",
        "            for j in range(0, width, self.pool_size):\n",
        "                # Extract the current pooling window\n",
        "                window = x[:, :, i:i + self.pool_size, j:j + self.pool_size]\n",
        "\n",
        "                # Compute mean and standard deviation for the window\n",
        "                mean = window.mean(dim=(2, 3), keepdim=True)\n",
        "                std = window.std(dim=(2, 3), keepdim=True) + 1e-8  # Avoid divide-by-zero\n",
        "\n",
        "                # Compute GMF (Gaussian Membership Function) values for the window\n",
        "                gmf = self.gaussian_membership(window, mean, std)\n",
        "\n",
        "                # Apply RegP to penalize dense activations\n",
        "                regp_total += self.regularization_penalty(gmf)\n",
        "\n",
        "                # Threshold: S-norm (max) followed by T-norm (min)\n",
        "                threshold = torch.min(torch.max(gmf, dim=3)[0], dim=2)[0].unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "                # Identify dominant features (only keep elements above the threshold)\n",
        "                dominant_features = window * (gmf >= threshold).float()\n",
        "\n",
        "                # Compute weighted average of the dominant features\n",
        "                weights = gmf / (gmf.sum(dim=(2, 3), keepdim=True) + 1e-8)\n",
        "                pooled_value = (dominant_features * weights).sum(dim=(2, 3))\n",
        "\n",
        "                # Assign the pooled value to the corresponding location in the output tensor\n",
        "                pooled_output[:, :, i // self.pool_size, j // self.pool_size] = pooled_value\n",
        "\n",
        "        # Add RegP penalty to the model as a regularization loss\n",
        "        self.regp_loss = regp_total / (batch_size * channels)  # Normalize by batch size and channels\n",
        "        return pooled_output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FuzzyCNNWithRegP(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Simple CNN with Fuzzy-Based Pooling Layer and RegP.\n",
        "        \"\"\"\n",
        "        super(FuzzyCNNWithRegP, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fuzzy_pool = FuzzyPoolingLayer(pool_size=2, reg_lambda=0.01)\n",
        "        self.fc1 = nn.Linear(32 * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.fuzzy_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten for FC layer\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def get_regp_loss(self):\n",
        "        \"\"\"\n",
        "        Retrieve the RegP loss from the pooling layer.\n",
        "        \"\"\"\n",
        "        return self.fuzzy_pool.regp_loss"
      ],
      "metadata": {
        "id": "NeFEnZbEKnMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dKIeVpKonyF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5763eb1-3e13-420d-af0d-ce89306d7720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3193, Accuracy: 91.08%\n",
            "Epoch [2/5], Loss: 0.1243, Accuracy: 96.47%\n",
            "Epoch [3/5], Loss: 0.0878, Accuracy: 97.51%\n",
            "Epoch [4/5], Loss: 0.0712, Accuracy: 97.95%\n",
            "Epoch [5/5], Loss: 0.0607, Accuracy: 98.25%\n"
          ]
        }
      ],
      "source": [
        "    # Initialize model, loss, and optimizer\n",
        "    modelR = FuzzyCNNWithRegP(num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(modelR.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train(modelR, train_loader, criterion, optimizer, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = test(modelR, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "3Ls7MxMhtGCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b603ea6b-9be0-4b95-f091-a13984ef3651"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0629, Test Accuracy: 98.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wbDP6VyzNlgY"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def model_summary(model, input_size=(1, 28, 28)):\n",
        "    \"\"\"\n",
        "    Print a summary of the model, including layers, output shapes, and parameter counts.\n",
        "\n",
        "    :param model: PyTorch model instance\n",
        "    :param input_size: Input shape for the model (excluding batch size)\n",
        "    \"\"\"\n",
        "    print(\"----- Model Summary -----\")\n",
        "    print(model)\n",
        "    print(\"\\n----- Layer-wise Details -----\")\n",
        "    summary(model, input_size=input_size)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(\"\\n----- Parameter Details -----\")\n",
        "    print(f\"Total Parameters: {total_params:,}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"Non-trainable Parameters: {total_params - trainable_params:,}\")\n",
        "\n",
        "    # If RegP is present, provide its status.\n",
        "    if hasattr(model, 'get_regp_loss'):\n",
        "        print(\"\\nRegP Enabled: Yes\")\n",
        "    else:\n",
        "        print(\"\\nRegP Enabled: No\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BMmIBzSUOc81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e125ea38-5bec-484c-cfc1-77409b6306e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Model Summary -----\n",
            "FuzzyCNNWithRegP(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fuzzy_pool): FuzzyPoolingLayer()\n",
            "  (fc1): Linear(in_features=6272, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "----- Layer-wise Details -----\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            " FuzzyPoolingLayer-2           [-1, 32, 14, 14]               0\n",
            "            Linear-3                   [-1, 10]          62,730\n",
            "================================================================\n",
            "Total params: 63,050\n",
            "Trainable params: 63,050\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.24\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.48\n",
            "----------------------------------------------------------------\n",
            "\n",
            "----- Parameter Details -----\n",
            "Total Parameters: 63,050\n",
            "Trainable Parameters: 63,050\n",
            "Non-trainable Parameters: 0\n",
            "\n",
            "RegP Enabled: Yes\n"
          ]
        }
      ],
      "source": [
        "model_summary(modelR, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_summary(modelFuzzy, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "xEEh7AERIh6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_summary(modelMax, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "buiRrI5BImpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtlMcmAoOjD5"
      },
      "outputs": [],
      "source": [
        "model_summary(modelAvg, input_size=(1, 28, 28))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}